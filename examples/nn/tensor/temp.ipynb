{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlfz.nn import Model, precast\n",
    "from mlfz.nn.tensor import Tensor, mean_squared_error, sum\n",
    "from mlfz.nn.tensor.functional import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def _finite_diff(f, x, h=1e-8):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for idx in np.ndindex(x.shape):\n",
    "        x_forward = x.copy()\n",
    "        x_backward = x.copy()\n",
    "        x_forward[idx] += h\n",
    "        x_backward[idx] -= h\n",
    "        grad[idx] = (f(x_forward) - f(x_backward)) / (2 * h)\n",
    "\n",
    "    return grad.reshape(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor(np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]))\n",
    "ys = [\n",
    "    Tensor(2),\n",
    "    Tensor(np.array([[7.0, 8.0], [9.0, 10.0], [11.0, 12.0]])),\n",
    "    Tensor(np.array([[1], [2], [3]])),\n",
    "    Tensor(np.array([1, 2])),\n",
    "]\n",
    "\n",
    "f = lambda x, y: (x * y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  7., 11.],\n",
       "       [ 3.,  7., 11.],\n",
       "       [ 3.,  7., 11.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = Tensor(np.array([[1], [2], [3]]))\n",
    "z = f(x, y)\n",
    "z.backward()\n",
    "\n",
    "y.backwards_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.99999989],\n",
       "       [ 6.99999987],\n",
       "       [10.99999984]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_finite_diff(partial(f, x.value), ys[2].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = Tensor(np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]))\n",
    "ys = [\n",
    "    Tensor(2),\n",
    "    Tensor(np.array([[7.0, 8.0], [9.0, 10.0], [11.0, 12.0]])),\n",
    "    Tensor(np.array([[1], [2], [3]])),\n",
    "    Tensor(np.array([1, 2])),\n",
    "]\n",
    "\n",
    "fs = [\n",
    "    # lambda x, y: (x + y).sum(),\n",
    "    # lambda x, y: (y + x).sum(),\n",
    "    lambda x, y: (x * y).sum(),\n",
    "    # lambda x, y: (y * x).sum(),\n",
    "    # lambda x, y: (x**y).sum(),\n",
    "    # lambda x, y: (x / y).sum(),\n",
    "]\n",
    "\n",
    "for f in fs:\n",
    "    for y in ys:\n",
    "        z = f(x, y)\n",
    "        z.backward()\n",
    "        print(np.allclose(\n",
    "            x.backwards_grad, _finite_diff(partial(f, y=y.value), x.value), 1e-2\n",
    "        ))\n",
    "        print(np.allclose(\n",
    "            y.backwards_grad, _finite_diff(partial(f, x.value), y.value), 1e-2\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
